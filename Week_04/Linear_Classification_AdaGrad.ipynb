{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Linear Classification with Gradient Descent",
   "id": "6fd943f2fd22b8e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:02:30.039680Z",
     "start_time": "2024-11-08T20:02:27.955478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import data_handler as dh"
   ],
   "id": "a4c877b48d32fcaf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fetching and Pre-Processing the data",
   "id": "370dfbb41848faaa"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T20:02:35.897349Z",
     "start_time": "2024-11-08T20:02:30.054686Z"
    }
   },
   "source": [
    "bank_marketing = fetch_ucirepo(id=222)\n",
    "occupancy_detection = fetch_ucirepo(id=357)\n",
    "\n",
    "X_bank_marketing, y_bank_marketing = bank_marketing.data.features, bank_marketing.data.targets\n",
    "X_occupancy, y_occupancy = occupancy_detection.data.features, occupancy_detection.data.targets"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pre-process the bank marketing data. Drop features without values for prediction: month, day_of_week. We have to treat NaN values differently than last week, since dropping them would drastically reduce the instances of the data, so we replace them with 0. We use One-Hot encoding for non-numeric (categorical) values. We use min-max normalization to avoid huge values for residuals.",
   "id": "dfac6cf81025488e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:02:36.843351Z",
     "start_time": "2024-11-08T20:02:36.744091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_bank_marketing = X_bank_marketing.drop(['month', 'day_of_week'], axis=1)  # drop features without value for prediction\n",
    "\n",
    "X_bank_marketing = X_bank_marketing.fillna(0)\n",
    "\n",
    "X_bank_marketing = pd.get_dummies(X_bank_marketing).astype(np.float64)\n",
    "\n",
    "X_bank_marketing = (X_bank_marketing - X_bank_marketing.min()) / (\n",
    "        X_bank_marketing.max() - X_bank_marketing.min())  # normalize the data"
   ],
   "id": "bf9064f00193ea0b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pre-process the occupancy data. Drop the date feature. Since all features are type object, we have to remove the standing out ones and convert them to numeric values. We use min-max normalization to avoid huge values for residuals.",
   "id": "20982ba06f510011"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:02:36.930666Z",
     "start_time": "2024-11-08T20:02:36.880618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_occupancy = X_occupancy.drop(['date'], axis=1)  # drop features without value for prediction\n",
    "\n",
    "X_occupancy = X_occupancy.apply(pd.to_numeric, errors='coerce').dropna().astype(\n",
    "    np.float64)  # Convert all columns to numeric, coerce errors to NaN, and drop rows with NaN values\n",
    "\n",
    "X_occupancy = (X_occupancy - X_occupancy.min()) / (X_occupancy.max() - X_occupancy.min())  # normalize the data"
   ],
   "id": "179c4197cbef6d2c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split the datasets in training data and test data. We use our method from `data_handler`.",
   "id": "834ff963f915bef4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:02:37.096261Z",
     "start_time": "2024-11-08T20:02:37.060574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_occupancy_train, X_occupancy_test, y_occupancy_train, y_occupancy_test = dh.split_data(X_occupancy,\n",
    "                                                                                         y_occupancy, 0.8)\n",
    "X_bank_marketing_train, X_bank_marketing_test, y_bank_marketing_train, y_bank_marketing_test = dh.split_data(\n",
    "    X_bank_marketing, y_bank_marketing, 0.8)"
   ],
   "id": "a97940a51c196caa",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementation of Linear Classification",
   "id": "8f2e543315114719"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:02:37.106896Z",
     "start_time": "2024-11-08T20:02:37.103271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LinearClassifier:\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "    "
   ],
   "id": "a72ef9df2079525",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
